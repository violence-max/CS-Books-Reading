> 在实际的工作场景中，经常会有竞争条件的产生，不同的进程会对临界区里的资源竞争使用权。因此，应当有一系列的方法来实现“同步”的机制，使得并发场景下满足进程的资源需求，同时又不会破坏临界区资源的稳定性。

常见的同步方法：原子操作和锁。  
<aside>
💡在编写代码的过程中，能使用原子操作时，就尽量不要使用复杂的锁机制。

</aside>

* 原子操作：对于变量在内存里的改变不会同时发生，即一个时刻只能有一个线程去修改这个变量  
<linux/types.h>中对原子整数的类型定义：  
```C
typedf struct {
    volatile int counter;
} atomic_t;
```  
显然，这只是32位的原子整数类型。但是，在早期原子整数类型诞生的时候，有的体系结构并不支持原子级的指令，因此只能在32位的原子整数类型的低8位加入一个锁来防止并发访问，也就是说这种情况下只有24位数据可以被使用到（显然Linux为了更好的兼容性牺牲了太多hh）。不过这个问题现在已经不存在了，所有的32位都可以被数据使用。   
对于64位的原子整数类型，Linux提供了`atomic64_t`的支持，原理就是将`volatile int counter`修改成了`volatile long counter`  。  
Linux提供了一系列的原子整数操作，可以在文件<asm/atomic.h>中找到。Linux还提供了一系列的原子位操作，可以在文件<asm/bitops.h>中找到。  

* 自旋锁：原子操作对于一些复杂的场景是无能为力的，比如对于一个数据结构当中若干数据的更改之后迁移到另一个数据结构中，这个过程必须是原子性的但是原子操作显然无法实现。在并发场景下，自旋锁至多只能被一个可执行线程持有，其余想要获取自旋锁的线程必须进行循环忙等待，直到获取锁之后才可以执行接下来的代码内容。  
有关自旋锁的定义在文件<linux/spinlock.h>中，自旋锁的基本使用形式如下：  
```C
DEFINE_SPINLOCK(mr_lock);
spin_lock(&mr_lock);
/*临界区*/
spin_unlock(&mr_lock);
```  
**自旋锁的适用场景**：从自旋锁的定义中可以发现，所有想要获取自旋锁的线程都必须进行忙等待循环以获取锁，这个过程其实消耗了CPU的资源。如果等待的过程线程可以睡眠，等锁被释放之后再被唤醒，那等待的过程CPU就可以去干点别的事情了。所以，自旋锁适用于临界区执行时间比较短的情况，最好是小于两次线程上下文切换的时间（虽然没人会去测量这个时间hh），因为在临界区锁被释放之后就包括了线程的换出和换入。  
**自旋锁是不可递归的**：如果一个持有锁A的线程还要持有锁A，那么它必须先等待自己释放这个锁，但是这是绝对不可能完成的操作，至少在Linux上不可能……  
**自旋锁可以适用在中断处理程序中**：虽然自旋锁在获取锁时需要忙等待，但是也有一个好处，那就是可以用在中断处理程序中，因为中断处理程序不允许睡眠hh。但是在中断处理程序中适用自旋锁一定要在获取锁之前禁止本地中断，否则本地的中断程序如果也要获取同一个锁，那就是典型的双重请求死锁了。关于这一点，Linux提供了`spin_lock_irqsave(&lock, flags)`来完成，这个（宏）函数可以保存当前中断状态，并且禁止本地中断。不过，如果是不同的处理器想要中断那是没问题的。  
**读写自旋锁**：读写自旋锁又被称作“共享/排斥锁”，多个读者共享，写者之间排斥。在并发的读场景下，多个读者可以持有同一个读锁，此时若是有写者想要写数据，那么必须等待所有读者都释放读锁之后才可以获取写锁。同理，读者获取读锁也必须等待写者释放写锁之后才可以读。因此读锁和写锁之间的临界区是不可以互相调用的。如果是对于读写操作非常清晰而且读操作数量远大于写操作数数量的场景，可以考虑适用读写自旋锁。在Linux里获取读锁和写锁的方式分别为：`read_lock()`和`write_lock()`。  

* 信号量：Linux里的信号量是一种睡眠锁，如果有一个任务视图获得一个不可用的信号量时，信号量会将其推入一个等待队列然后让其睡眠，此时处理器被释放，可以去执行其它任务。但信号量被释放后，处于等待队列中的任务被唤醒，并获得该信号量。  
**信号量适用场景**：适用于锁会被长时间持有的情况，并且只能在进程上下文中持有信号量锁，因为中断上下文中不能进行调度。在持有信号量锁的情况下最好别获取自旋锁，因为等待信号量时可能睡眠，而持有自旋锁时不允许睡眠。  
**PV操作**：远古时期的信号量通过PV操作来描述，P操作负责将信号量的引用计数减一而V操作负责减信号量的引用计数加一。如果在适用P操作之后返回的信号量的值大于或者等于0，那么视为可以持有这个信号量。这样的定义使得信号量的初始化更加具有个性化，因为可以初始化一个信号量的引用计数来规定至多有多少个线程可以获取信号量锁，同时也使得适用场景更加通用以及复杂，比如用户态与内核态之间的交互场景，需要在一个上下文中上锁在另一个上下文中解锁。  
**读写信号量**：与读写自旋锁一样，Linux提供了读写信号量机制，像是一个可以睡眠的自旋锁。  

* 互斥锁：大名鼎鼎的mutex。  
mutex的适用场景比信号量要严格的多，但是和信号量一样，如果在获取锁时锁不可用那么线程需要加入等待队列然后睡眠。  
任何时刻只有一个任务可以持有mutex，即mutex的引用计数永远是1；  
只能在同一上下文中对mutex进行上锁和解锁的操作；  
不允许递归地上锁和解锁；  
当持有锁时进程不允许退出；  
互斥锁和信号量非常相似，但是在适用于这种睡眠锁的场景下，除非以上的某个约束条件妨碍了适用，否则相比于信号量要优先考虑互斥锁，我们都喜欢简单的场景不是吗？没有其它选择时才会选择信号量。  

* 条件变量：Linux在<linux/completion.h>中定义了名为完成变量的数据结构，并且提供了以下三个API：  
1. `init_completion(struct completion*)`：初始化指定的动态创建的条件变量
2. `wait_for_completion(struct completion*)`：等待指定的条件变量接收信号
3. `complete(struct completion*)`：发信号唤醒任何等待任务  
通过条件变量，可以实现两个任务之间的同步。  

* 内存屏障：现代处理器为了优化其传送管道有可能会打乱分派和提交指令的顺序，使得某些不互相依赖的写操作或者读操作之间发生乱序的情况。  
比如下面这个例子：  
```C
// a初始值为1，b初始值为2
//线程1       //线程2
a = 3;          
b = 4;       
             c = b;
             d = a;
```
如果在c和d的读取之间没有加入内存屏障，那么c有可能接收b的新值4而d可能接收a的旧值1。  
常见的内存屏障方法：  
1. rmb()：提供了一个读内存屏障，确保跨越rmb()操作的载入动作不会重排序
2. wmb()：提供了一个写内存屏障，确保跨越wmb()操作的存储动作不会重排序
3. mb()：提供了读写内存屏障，跨越mb()的载入和存储动作都不会重排序  

其它有趣的锁：顺序锁、大内核锁等。  

参考资料：
1. Linux内核设计与实现第三版，Robert Love，陈莉君、康华译，机械工业出版社